import pandas as pd
from ProvGraph import ProvGraph, ProcNode, FileNode, RequestNode, EdgeType
import os
import json

import os


DEBUG = False
DRAW_GRAPH = False

if DEBUG:
    pd.set_option('display.max_columns', None)
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_colwidth', None)

total = pd.read_json("./capture/capture.jsonl", lines=True, dtype={
    "proc.vpid": str, "proc.cvpid": str, "proc.pvpid": str, "thread.vtid": str
    , "thread.pvtid": str, "thread.cvtid": str, "evt.num": str, "evt.arg.data": str})
# 去掉postgresql的行
total = total[total["proc.name"] != "postgres"]

def get_unique_ordered_names(group):  
    # 保持顺序的唯一值提取  
    names = []  
    for name in group['proc.name']:  
        if name not in names:  
            names.append(name)  
    return names 
    

unique_names = total.groupby("thread.vtid", sort=False).apply(get_unique_ordered_names)

for vpid, names in unique_names.items():
    if len(names) == 1:
        continue
    # 把多个名字的进程用->连接起来
    new_name = "->".join(names)
    total.loc[total["thread.vtid"] == vpid, "proc.name"] = new_name

proc_groups = total.groupby("thread.vtid", sort=False)

def get_grouped_data(data: pd.DataFrame) -> dict:
    data = data[data["proc.name"] == "pgadmin4"].copy()
    # python_data["proc.vpid"] = python_data["proc.vpid"].astype(int)
    return data.groupby("thread.vtid", sort=False)


def analyze_request_files(request_id: str, data: pd.DataFrame) -> ProvGraph:
    # 迭代每一行，寻找type=file的行
    graph = ProvGraph()
    graph.add_node(RequestNode(request_id))
    file_data = data[(data["evt.category"] == "file") & (data["fd.name"] != "/dev/null")]
    # print(file_data)
    unmatched_copy = None
    for _, row in file_data.iterrows():
        if row["fd.name"] == "/var/log/pgadmin/pgadmin4.log":
            continue
        if row["evt.type"] == "read" or row["evt.type"] == "pread":
            pass
            # graph.add_event_edge(FileNode(row["fd.name"], row["fd.type"] == "directory"), RequestNode(request_id), EdgeType.READ, row["evt.datetime"])
        elif row["evt.type"] == "write" or row["evt.type"] == "pwrite" \
             or ((row["evt.type"] == "open" or row["evt.type"] == "openat") and ("O_F_CREATED" not in row["evt.info"]) and ("O_TRUNC" in row["evt.info"])):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.WRITE, row["evt.datetime"], row["evt.arg.data"])
        elif row["evt.type"] == "copy_file_range":
            if row["evt.dir"] == ">":
                unmatched_copy = (FileNode(row["fd.name"], row["fd.type"] == "directory"), RequestNode(request_id), EdgeType.COPY_FROM, row["evt.datetime"])
            elif row["evt.dir"] == "<":
                if unmatched_copy is not None:
                    # graph.add_event_edge(*unmatched_copy)
                    graph.add_event_edge(RequestNode(request_id), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY_TO, row["evt.datetime"])
                    graph.add_event_edge(FileNode(unmatched_copy[0].name, row["fd.type"] == "directory"), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY, row["evt.datetime"])
                    unmatched_copy = None
        elif (row["evt.type"] == "open" or row["evt.type"] == "openat") and "O_F_CREATED" in row["evt.info"]:
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.CREATE, row["evt.datetime"])
        elif (row["evt.type"] == "unlink" or row["evt.type"] == "unlinkat") and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.DELETE, row["evt.datetime"])
        elif (row["evt.type"] == "chmod") and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.CHMOD, row["evt.datetime"])
        elif (row["evt.type"] == "chown") and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.CHOWN, row["evt.datetime"])
        elif row["evt.type"] == "mkdir" and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"], is_dir=True), EdgeType.MKDIR, row["evt.datetime"])
        elif row["evt.type"] == "rmdir" and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"], is_dir=True), EdgeType.RMDIR, row["evt.datetime"])
        elif (row["evt.type"] == "renameat2" or row["evt.type"] == "renameat" or row["evt.type"] == "rename") and row["evt.info"].startswith("res=0"):
            # graph.add_event_edge(FileNode(row["fs.path.source"]), RequestNode(request_id), "rename_source", row["evt.datetime"])
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.target"], not row["fs.path.source"].endswith(".txt")), EdgeType.RENAME_TARGET, row["evt.datetime"])
            graph.add_event_edge(FileNode(row["fs.path.source"], not row["fs.path.source"].endswith(".txt")), FileNode(row["fs.path.target"], not row["fs.path.source"].endswith(".txt")), EdgeType.RENAME, row["evt.datetime"])

    return graph


def analyze_request_subprocesses(data: pd.DataFrame) -> list:
    request_subprocesses = []
    subprocess_data = data[(data["evt.type"] == "clone") | (data["evt.type"] == "vfork")]
    # print(subprocess_data)
    for _, row in subprocess_data.iterrows():
        request_subprocesses.append(row["thread.cvtid"])
    
    return request_subprocesses


def analyze_single_process_data(name: str, group: pd.DataFrame) -> dict:
    if group["evt.type"].iloc[0] != "recvfrom":
        print(f"{name} no request found")
        return None, None
    
    request_info = group["evt.arg.data"].iloc[0]
    curr_fd = group["fd.name"].iloc[0]
    for i in range(1, len(group)):
        if group["evt.type"].iloc[i] == "recvfrom" and group["fd.name"].iloc[i] == curr_fd:
            request_info += group["evt.arg.data"].iloc[i]
    
    group["request_info"] = request_info
    group["request_id"] = name
    
    # 按照request_id分组
    result = ({}, {})
    result_info_map = {}
    print(f"Analyzing request {name}")
    request_graph = analyze_request_files(name, group)
    result[0][name] = request_graph
    request_subprocesses = analyze_request_subprocesses(group)
    result[1][name] = request_subprocesses
    result_info_map[name] = group.iloc[0]["request_info"]

    return result, result_info_map


def build_graph(request_id: str, vpids: list, graph: ProvGraph | None = None) -> ProvGraph:
    graph = ProvGraph() if graph is None else graph
    graph.add_node(RequestNode(request_id))
    unmatched_copy = None
    for vpid in vpids:
        try:
            proc_data = proc_groups.get_group(vpid)
            graph.add_event_edge(RequestNode(request_id), ProcNode(vpid, proc_data.iloc[0]["proc.name"]), EdgeType.CREATE_SUBPROCESS, proc_data.iloc[0]["evt.datetime"])
        except KeyError:
            # graph.add_event_edge(RequestNode(request_id), ProcNode(vpid, "unknown"), EdgeType.CREATE_SUBPROCESS, proc_data.iloc[0]["evt.datetime"])
            continue
    while len(vpids) > 0:
        vpid = vpids.pop()
        try:
            proc_data = proc_groups.get_group(vpid)
        except KeyError:
            continue
        for _, row in proc_data.iterrows():
            if row["evt.category"] == "file":
                if row["fd.name"] == "/var/log/pgadmin/pgadmin4.log":
                    continue
                if row["evt.type"] == "read" or row["evt.type"] == "pread":
                    pass
                    # graph.add_event_edge(FileNode(row["fd.name"], row["fd.type"] == "directory"), ProcNode(vpid, proc_data.iloc[0]["proc.name"]), EdgeType.READ, row["evt.datetime"])
                elif row["evt.type"] == "write" or row["evt.type"] == "pwrite" \
                    or ((row["evt.type"] == "open" or row["evt.type"] == "openat") and ("O_F_CREATED" not in row["evt.info"]) and ("O_TRUNC" in row["evt.info"])):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.WRITE, row["evt.datetime"], row["evt.arg.data"])
                elif row["evt.type"] == "copy_file_range":
                    if row["evt.dir"] == ">":
                        unmatched_copy = (FileNode(row["fd.name"], row["fd.type"] == "directory"), ProcNode(vpid, proc_data.iloc[0]["proc.name"]), EdgeType.COPY_FROM, row["evt.datetime"])
                    elif row["evt.dir"] == "<":
                        if unmatched_copy is not None:
                            # graph.add_event_edge(*unmatched_copy)
                            graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY_TO, row["evt.datetime"])
                            graph.add_event_edge(FileNode(unmatched_copy[0].name), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY, row["evt.datetime"])
                            unmatched_copy = None
                elif (row["evt.type"] == "open" or row["evt.type"] == "openat") and "O_F_CREATED" in row["evt.info"]:
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.CREATE, row["evt.datetime"])
                elif (row["evt.type"] == "unlink" or row["evt.type"] == "unlinkat") and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.name"]), EdgeType.DELETE, row["evt.datetime"])
                elif (row["evt.type"] == "chmod") and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.name"]), EdgeType.CHMOD, row["evt.datetime"])
                elif (row["evt.type"] == "chown") and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.name"]), EdgeType.CHOWN, row["evt.datetime"])
                elif row["evt.type"] == "mkdir" and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.name"], is_dir=True), EdgeType.MKDIR, row["evt.datetime"])
                elif row["evt.type"] == "rmdir" and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.name"], is_dir=True), EdgeType.RMDIR, row["evt.datetime"])
                elif (row["evt.type"] == "renameat2" or row["evt.type"] == "renameat" or row["evt.type"] == "rename") and row["evt.info"].startswith("res=0"):
                    # graph.add_event_edge(FileNode(row["fs.path.source"]), ProcNode(vpid, proc_data.iloc[0]["proc.name"]), "rename_source", row["evt.datetime"])
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.target"], not row["fs.path.source"].endswith(".txt")), EdgeType.RENAME_TARGET, row["evt.datetime"])
                    graph.add_event_edge(FileNode(row["fs.path.source"], not row["fs.path.source"].endswith(".txt")), FileNode(row["fs.path.target"], not row["fs.path.source"].endswith(".txt")), EdgeType.RENAME, row["evt.datetime"])
            if row["evt.type"] == "clone" or row["evt.type"] == "vfork":
                try:
                    cproc_data = proc_groups.get_group(row["thread.cvtid"])
                    vpids.append(row["thread.cvtid"])
                    graph.add_event_edge(ProcNode(vpid, row["proc.name"]), ProcNode(row["thread.cvtid"], cproc_data.iloc[0]["proc.name"]), EdgeType.CREATE_SUBPROCESS, row["evt.datetime"])
                except KeyError:
                    graph.add_event_edge(ProcNode(vpid, row["proc.name"]), ProcNode(row["thread.cvtid"], "unknown"), EdgeType.CREATE_SUBPROCESS, row["evt.datetime"])
    return graph
            

def analyze_results():
    results = {}
    req_info = {}
    matchare_res = {}
    total_requests = 0
    grouped_data = get_grouped_data(total)
    os.system("rm -rf ./prov_graphs/*")
    os.system("rm -rf ./request_data/*")

    for name, group in grouped_data:
        print(f"Analyzing process {name}")
        analyzed_data, req_info_map = analyze_single_process_data(name, group)
        if analyzed_data is not None:
            req_info |= req_info_map
            total_requests += len(analyzed_data[0])
            for request_id, vpids in analyzed_data[1].items():
                graph = analyzed_data[0][request_id]
                graph = build_graph(request_id, vpids, graph)
                if DRAW_GRAPH:
                    graph.draw_graph(file_name=f"prov_graph_{request_id}", show=False, save_path="./prov_graphs/")
                affected_files = graph.find_affected_files(RequestNode(request_id))
                results[request_id] = affected_files
                matchare_res[request_id] = graph.find_related_files(RequestNode(request_id))
    print(f"Total requests: {total_requests}")
    print("Done!")
    with open("fs_results.json", "w") as out:
        out.write(json.dumps(results, indent=4))
    with open("req_info.json", "w") as out:
        out.write(json.dumps(req_info, indent=4))
    with open("matchare_res.json", "w") as out:
        out.write(json.dumps(matchare_res, indent=4))

    return results

if __name__ == "__main__":
    start_time = pd.Timestamp.now()
    analyze_results()
    end_time = pd.Timestamp.now()
    # 毫秒级别
    elapsed_time = (end_time - start_time).total_seconds() * 1000
    print(f"分析时间: {elapsed_time} ms")
    pass