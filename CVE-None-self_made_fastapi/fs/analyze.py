import pandas as pd
from ProvGraph import ProvGraph, ProcNode, FileNode, RequestNode, EdgeType
import os
import json
import re
from collections import deque


DEBUG = False
DRAW_GRAPH = False

if DEBUG:
    pd.set_option('display.max_columns', None)
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_colwidth', None)

total = pd.read_json("./capture/capture.jsonl", lines=True, dtype={"proc.vpid": str, "proc.cvpid": str, "proc.pvpid": str, "thread.vtid": str})

# 去掉postgresql的行
total = total[total["proc.name"] != "postgres"]

def get_unique_ordered_names(group):  
    # 保持顺序的唯一值提取  
    names = []  
    for name in group['proc.name']:  
        if name not in names:  
            names.append(name)  
    return names 
    

unique_names = total.groupby("proc.vpid", sort=False).apply(get_unique_ordered_names)

for vpid, names in unique_names.items():
    if len(names) == 1:
        continue
    # 把多个名字的进程用->连接起来
    new_name = "->".join(names)
    total.loc[total["proc.vpid"] == vpid, "proc.name"] = new_name

proc_groups = total.groupby("proc.vpid", sort=False)

def get_grouped_data(data: pd.DataFrame) -> dict:
    data = data[data["proc.name"] == "python"].copy()
    # python_data["proc.vpid"] = python_data["proc.vpid"].astype(int)
    return data.groupby("proc.vpid", sort=False)


def analyze_request_files(request_id: str, data: pd.DataFrame) -> ProvGraph:
    # 迭代每一行，寻找type=file的行
    graph = ProvGraph()
    graph.add_node(RequestNode(request_id))
    file_data = data[(data["evt.category"] == "file") & (data["fd.name"] != "/dev/null")]
    # print(file_data)
    unmatched_copy = None
    for _, row in file_data.iterrows():
        if row["evt.type"] == "read" or row["evt.type"] == "pread":
            pass
            # graph.add_event_edge(FileNode(row["fd.name"], row["fd.type"] == "directory"), RequestNode(request_id), EdgeType.READ, row["evt.datetime"])
        elif row["evt.type"] == "write" or row["evt.type"] == "pwrite" \
             or ((row["evt.type"] == "open" or row["evt.type"] == "openat") and ("O_F_CREATED" not in row["evt.info"]) and ("O_TRUNC" in row["evt.info"])):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.WRITE, row["evt.datetime"], row["evt.arg.data"])
        elif row["evt.type"] == "copy_file_range":
            if row["evt.dir"] == ">":
                unmatched_copy = (FileNode(row["fd.name"], row["fd.type"] == "directory"), RequestNode(request_id), EdgeType.COPY_FROM, row["evt.datetime"])
            elif row["evt.dir"] == "<":
                if unmatched_copy is not None:
                    # graph.add_event_edge(*unmatched_copy)
                    graph.add_event_edge(RequestNode(request_id), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY_TO, row["evt.datetime"])
                    graph.add_event_edge(FileNode(unmatched_copy[0].name), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY, row["evt.datetime"])
                    unmatched_copy = None
        elif (row["evt.type"] == "open" or row["evt.type"] == "openat") and "O_F_CREATED" in row["evt.info"]:
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.CREATE, row["evt.datetime"])
        elif (row["evt.type"] == "unlink" or row["evt.type"] == "unlinkat") and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.DELETE, row["evt.datetime"])
        elif (row["evt.type"] == "chmod") and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.CHMOD, row["evt.datetime"])
        elif (row["evt.type"] == "chown") and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.CHOWN, row["evt.datetime"])
        elif row["evt.type"] == "mkdir" and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"], True), EdgeType.MKDIR, row["evt.datetime"])
        elif row["evt.type"] == "rmdir" and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"], True), EdgeType.RMDIR, row["evt.datetime"])
        elif (row["evt.type"] == "renameat2" or row["evt.type"] == "renameat" or row["evt.type"] == "rename") and row["evt.info"].startswith("res=0"):
            # graph.add_event_edge(FileNode(row["fs.path.source"]), RequestNode(request_id), "rename_source", row["evt.datetime"])
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.target"]), EdgeType.RENAME_TARGET, row["evt.datetime"])
            graph.add_event_edge(FileNode(row["fs.path.source"]), FileNode(row["fs.path.target"]), EdgeType.RENAME, row["evt.datetime"])
    
    return graph


def analyze_request_subprocesses(data: pd.DataFrame) -> list:
    request_subprocesses = []
    subprocess_data = data[(data["evt.type"] == "clone") | (data["evt.type"] == "vfork")]
    # print(subprocess_data)
    for _, row in subprocess_data.iterrows():
        request_subprocesses.append(row["proc.cvpid"])
    
    return request_subprocesses


HTTP_METHODS = ["GET", "POST", "HEAD", "PUT", "DELETE", "OPTIONS", "PATCH", "CONNECT", "TRACE"]
def analyze_single_process_data(name: str, data: pd.DataFrame) -> dict:
    req_infos = deque()
    request_data_dict: dict[str, list] = {}
    req_info_dict: dict[str, str] = {}
    delimiter_re = re.compile(
        r".*python (request_start|request_init) (\d+-\d+)(.*)", re.DOTALL
    )

    data["evt.arg.data"] = data["evt.arg.data"].fillna("NULL")
    data = data.reset_index(drop=True)
    current_id = None
    for index, row in data.iterrows():
        if row["evt.type"] == "recvfrom" and row["evt.category"] == "net" and row["evt.arg.data"].split(" ")[0] in HTTP_METHODS:
            req_info = row["evt.arg.data"]
            if index < len(data) - 1:
                next_ = data.iloc[index + 1]
                if next_["evt.type"] == "recvfrom" and next_["evt.category"] == "net" and next_["fd.name"] == row["fd.name"]:
                    req_info += next_["evt.arg.data"]
            req_infos.append(req_info)
            continue
        if "request_init" in row["evt.arg.data"]:
            req_id = delimiter_re.match(row["evt.arg.data"]).group(2)
            current_id = req_id
            request_data_dict[req_id] = []
            req_info_dict[req_id] = req_infos.popleft()
            continue
        if "request_start" in row["evt.arg.data"]:
            req_id = delimiter_re.match(row["evt.arg.data"]).group(2)
            # if req_id not in request_data_dict:
            #     print(req_id)
            current_id = req_id
            continue
        
        if current_id is not None and current_id.split("-")[1] != "0":
            try:
                request_data_dict[current_id].append(row)
            except KeyError:
                pass
    
    for key, value in request_data_dict.items():
        request_data_dict[key] = pd.DataFrame(value)
        request_data_dict[key].loc[:,"request_info"] = req_info_dict[key]
        request_data_dict[key].loc[:,"request_id"] = key

    if len(request_data_dict) == 0:
        print(f"Process {name} has no requests.")
        return None, None
    
    print(f"Process {name} has {len(request_data_dict)} requests.")
    # 按照request_id分组
    result = ({}, {})
    result_info_map = {}
    for request_id, group in request_data_dict.items():
        # if type(group) != pd.DataFrame:
        #     group = pd.DataFrame(group)
        #     group.to_json(f"request_data/{request_id}.jsonl", orient="records", lines=True)
        print(f"Analyzing request {request_id}")
        request_graph = analyze_request_files(request_id, group)
        result[0][request_id] = request_graph
        request_subprocesses = analyze_request_subprocesses(group)
        result[1][request_id] = request_subprocesses
        result_info_map[request_id] = group.iloc[0]["request_info"]

    return result, result_info_map


def build_graph(request_id: str, vpids: list, graph: ProvGraph | None = None) -> ProvGraph:
    graph = ProvGraph() if graph is None else graph
    graph.add_node(RequestNode(request_id))
    unmatched_copy = None
    for vpid in vpids:
        try:
            proc_data = proc_groups.get_group(vpid)
            graph.add_event_edge(RequestNode(request_id), ProcNode(vpid, proc_data.iloc[0]["proc.name"]), EdgeType.CREATE_SUBPROCESS, proc_data.iloc[0]["evt.datetime"])
        except KeyError:
            # graph.add_event_edge(RequestNode(request_id), ProcNode(vpid, "unknown"), EdgeType.CREATE_SUBPROCESS, proc_data.iloc[0]["evt.datetime"])
            continue
    while len(vpids) > 0:
        vpid = vpids.pop()
        try:
            proc_data = proc_groups.get_group(vpid)
        except KeyError:
            continue
        for _, row in proc_data.iterrows():
            if row["evt.category"] == "file":
                if row["evt.type"] == "read" or row["evt.type"] == "pread":
                    pass
                    # graph.add_event_edge(FileNode(row["fd.name"], row["fd.type"] == "directory"), ProcNode(vpid, proc_data.iloc[0]["proc.name"]), EdgeType.READ, row["evt.datetime"])
                elif row["evt.type"] == "write" or row["evt.type"] == "pwrite" \
                    or ((row["evt.type"] == "open" or row["evt.type"] == "openat") and ("O_F_CREATED" not in row["evt.info"]) and ("O_TRUNC" in row["evt.info"])):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.WRITE, row["evt.datetime"], row["evt.arg.data"])
                elif row["evt.type"] == "copy_file_range":
                    if row["evt.dir"] == ">":
                        unmatched_copy = (FileNode(row["fd.name"], row["fd.type"] == "directory"), ProcNode(vpid, proc_data.iloc[0]["proc.name"]), EdgeType.COPY_FROM, row["evt.datetime"])
                    elif row["evt.dir"] == "<":
                        if unmatched_copy is not None:
                            # graph.add_event_edge(*unmatched_copy)
                            graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY_TO, row["evt.datetime"])
                            graph.add_event_edge(FileNode(unmatched_copy[0].name), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY, row["evt.datetime"])
                            unmatched_copy = None
                elif (row["evt.type"] == "open" or row["evt.type"] == "openat") and "O_F_CREATED" in row["evt.info"]:
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.CREATE, row["evt.datetime"])
                elif (row["evt.type"] == "unlink" or row["evt.type"] == "unlinkat") and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.name"]), EdgeType.DELETE, row["evt.datetime"])
                elif (row["evt.type"] == "chmod") and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.name"]), EdgeType.CHMOD, row["evt.datetime"])
                elif (row["evt.type"] == "chown") and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.name"]), EdgeType.CHOWN, row["evt.datetime"])
                elif row["evt.type"] == "mkdir" and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.name"], True), EdgeType.MKDIR, row["evt.datetime"])
                elif row["evt.type"] == "rmdir" and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.name"], True), EdgeType.RMDIR, row["evt.datetime"])
                elif (row["evt.type"] == "renameat2" or row["evt.type"] == "renameat" or row["evt.type"] == "rename") and row["evt.info"].startswith("res=0"):
                    # graph.add_event_edge(FileNode(row["fs.path.source"]), ProcNode(vpid, proc_data.iloc[0]["proc.name"]), "rename_source", row["evt.datetime"])
                    graph.add_event_edge(ProcNode(vpid, proc_data.iloc[0]["proc.name"]), FileNode(row["fs.path.target"]), EdgeType.RENAME_TARGET, row["evt.datetime"])
                    graph.add_event_edge(FileNode(row["fs.path.source"]), FileNode(row["fs.path.target"]), EdgeType.RENAME, row["evt.datetime"])
            if row["evt.type"] == "clone" or row["evt.type"] == "vfork":
                try:
                    cproc_data = proc_groups.get_group(row["proc.cvpid"])
                    vpids.append(row["proc.cvpid"])
                    graph.add_event_edge(ProcNode(vpid, row["proc.name"]), ProcNode(row["proc.cvpid"], cproc_data.iloc[0]["proc.name"]), EdgeType.CREATE_SUBPROCESS, row["evt.datetime"])
                except KeyError:
                    graph.add_event_edge(ProcNode(vpid, row["proc.name"]), ProcNode(row["proc.cvpid"], "unknown"), EdgeType.CREATE_SUBPROCESS, row["evt.datetime"])
    return graph
            

def analyze_results():
    results = {}
    req_info = {}
    matchare_res = {}
    total_requests = 0
    grouped_data = get_grouped_data(total)
    os.system("rm -rf ./prov_graphs/*")
    os.system("rm -rf ./request_data/*")

    for name, group in grouped_data:
        print(f"Analyzing process {name}")
        analyzed_data, req_info_map = analyze_single_process_data(name, group)
        if analyzed_data is not None:
            req_info |= req_info_map
            total_requests += len(analyzed_data[0])
            for request_id, vpids in analyzed_data[1].items():
                graph = analyzed_data[0][request_id]
                graph = build_graph(request_id, vpids, graph)
                if DRAW_GRAPH:
                    graph.draw_graph(file_name=f"prov_graph_{request_id}", show=False, save_path="./prov_graphs/")
                affected_files = graph.find_affected_files(RequestNode(request_id))
                results[request_id] = affected_files
                matchare_res[request_id] = graph.find_related_files(RequestNode(request_id))
    print(f"Total requests: {total_requests}")
    print("Done!")
    with open("fs_results.json", "w") as out:
        out.write(json.dumps(results, indent=4))
    with open("req_info.json", "w") as out:
        out.write(json.dumps(req_info, indent=4))
    with open("matchare_res.json", "w") as out:
        out.write(json.dumps(matchare_res, indent=4))

    return results

if __name__ == "__main__":
    analyze_results()
    pass