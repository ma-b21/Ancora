from pprint import pprint
import re
import os
import pandas as pd
pd.set_option('future.no_silent_downcasting', True)  
import json
import time

DEBUG = False

if DEBUG:
    pd.set_option('display.max_columns', None)
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_colwidth', None)

data = pd.read_json("./capture/capture.jsonl", lines=True, dtype={"proc.vpid": str, "proc.cvpid": str, "proc.pvpid": str, "thread.vtid": str})

def analyze_postgres_data(data: pd.DataFrame) -> pd.DataFrame:
    log_re = re.compile(
        r".*?\[([0-9\.]+\(\d+\))\].*?LOG:  statement: (.*)", re.DOTALL
    )

    data = data.copy()
    # 如果evt.arg.data为None，去掉该行
    data = data[data["evt.arg.data"].notna()]
    # 非数据库日志丢弃
    data = data[data["evt.arg.data"].apply(
        lambda x: "LOG:" in x
    )]
    # 提取数据库连接
    data["client_tuple"] = data["evt.arg.data"].apply(
        lambda x: log_re.match(x).group(1) if log_re.match(x) else None
    )

    def get_stmt(x):
        stmt = log_re.match(x).group(2)
        stmts = stmt.split("--")[0].split(";")
        stmt = ';'.join([stm for stm in stmts if "SELECT" not in stm])
        return stmt.strip()
    data["statement"] = data["evt.arg.data"].apply(
        lambda x: get_stmt(x) if log_re.match(x) else None
    )
    # data["details"] = data["evt.arg.data"].apply(
    #     lambda x: log_re.match(x).group(3) if log_re.match(x) else None
    # )

    return data


def extract_tuple_for_single_request(data: pd.DataFrame) -> pd.DataFrame:
    # 提取数据库连接
    connection_re = re.compile(
        r"(\d+.\d+.\d+.\d+):(\d+)->(\d+.\d+.\d+.\d+):5432"
    )
    # fd.name为None的行补为空字符串
    try:
        data["fd.name"] = data["fd.name"].fillna("NULL")
    except:
        # print(data)
        raise
    data["client_tuple"] = data["fd.name"].apply(
        lambda x: f"{connection_re.match(x).group(1)}({connection_re.match(x).group(2)})"
        if connection_re.match(x) else None
    )
    data["client_tuple"] = data["client_tuple"].ffill()
    data["client_tuple"] = data["client_tuple"].bfill()
    return data


if __name__ == "__main__":
    os.system("rm -f ./request_data/*")
    # data按thread.tid分组
    start_time = time.time()
    server_data = data[data["proc.name"] == "gunicorn"]
    grouped_data = server_data.groupby("proc.vpid", sort=False)

    postgres_data = data[data["proc.name"] == "postgres"]
    postgres_data = analyze_postgres_data(postgres_data)
    # postgres_data.to_json("postgres_data.jsonl", orient="records", lines=True)
    # 将single_process_data每行数据作为json格式输出
    # single_process_data.to_json("single_process_data.jsonl", orient="records", lines=True)
    length = 0
    request_data_dict: dict[str, list] = {}
    for name, group in grouped_data:
        if name == 1:
            continue
        in_request = False
        request_id = 0
        current_fd = None
        request_info = None
        src_ip = None
        # 针对每个进程
        # group.to_json(f"request_data/{name}.jsonl", orient="records", lines=True)
        for _, row in group.iterrows():
            # 根据accept4和close事件来判断请求的开始和结束
            if row["evt.type"] == "accept4" and row["fd.name"] != "NULL":
                length += 1
                if in_request:
                    request_data_dict[f"{name}-{request_id}"] = pd.DataFrame(request_data_dict[f"{name}-{request_id}"])
                    request_data_dict[f"{name}-{request_id}"]["request_info"] = request_info
                    request_info = None
                in_request = True
                current_fd = row["fd.name"]
                request_id += 1
                request_data_dict[f"{name}-{request_id}"] = []
            if in_request:
                request_data_dict[f"{name}-{request_id}"].append(row)
                if row["evt.type"] == "recvfrom" and row["fd.name"] == current_fd:
                    if not request_info:
                        request_info = ""
                    request_info += row["evt.arg.data"]

            if row["evt.type"] == "close" and row["fd.name"] == current_fd:
                in_request = False
                current_fd = None
                # 把数据转换为DataFrame
                request_data_dict[f"{name}-{request_id}"] = pd.DataFrame(request_data_dict[f"{name}-{request_id}"])
                request_data_dict[f"{name}-{request_id}"]["request_info"] = request_info
                request_info = None
    
    aggregated_data = pd.DataFrame()
    print("length:", length)
    print("request_data_dict:", len(request_data_dict))
    
    if length == 0:
        print("没有请求数据")
        exit(0)
    for key, value in request_data_dict.items():
        # 提取每个请求的数据库连接
        if not isinstance(value, pd.DataFrame):
            value = pd.DataFrame(value)
        request_data_dict[key] = extract_tuple_for_single_request(value)
        request_data_dict[key]["request_id"] = key
        # request_data_dict[key].to_json(f"request_data/{key}.jsonl", orient="records", lines=True)
        aggregated_data = pd.concat([aggregated_data, request_data_dict[key]])

    aggregated_data = pd.concat([aggregated_data, postgres_data])
    def match_id_database(group: pd.DataFrame) -> pd.DataFrame:
        group = group.sort_values("evt.datetime")
        group["request_id"] = group["request_id"].ffill()
        group["request_id"] = group["request_id"].bfill()
        group["request_info"] = group["request_info"].ffill()
        group["request_info"] = group["request_info"].bfill()
        return group
    matched_data = aggregated_data.groupby("client_tuple", sort=False).apply(
        match_id_database, include_groups=True
    ).groupby("proc.name", sort=False).get_group("postgres").sort_values("evt.datetime")
    # 丢弃没有request_id的行
    matched_data = matched_data[matched_data["request_id"].notna()]
    matched_data.to_json("matched_data.jsonl", orient="records", lines=True)
    # 将matched_data中的request_id和statement用字典形式输出, result[request_id] = [statement1, statement2]
    result = {}
    for _, row in matched_data.iterrows():
        # if str(row["request_id"]) == "NaN":
        #     continue
        if row["request_id"] not in result:
            result[row["request_id"]] = {
                "request_info": row["request_info"],
                "statement": []
            }
        if row["statement"]:
            result[row["request_id"]]["statement"].append(row["statement"])

    # 将结果输出为json格式
    with open("db_results.json", "w") as f:
        print(len(result))
        json.dump(result, f, indent=2)
    endtime = time.time()
    print("总耗时:", (endtime - start_time) * 1000, "ms")
    print("数据处理完毕")