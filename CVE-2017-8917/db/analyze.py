from pprint import pprint
import re
import os
import pandas as pd
pd.set_option('future.no_silent_downcasting', True)  
import json

DEBUG = False

if DEBUG:
    pd.set_option('display.max_columns', None)
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_colwidth', None)

data = pd.read_json("./capture/capture.jsonl", lines=True, dtype={"proc.vpid": str, "proc.cvpid": str, "proc.pvpid": str, "thread.vtid": str})

def analyze_mysql_data(data: pd.DataFrame) -> pd.DataFrame:
    # groups = data.groupby("thread.tid", sort=False)
    def extract_tuple(group: pd.DataFrame) -> pd.DataFrame:
        # 提取数据库连接
        connection_re = re.compile(
            r"(\d+.\d+.\d+.\d+):(\d+)->(\d+.\d+.\d+.\d+):3306"
        )
        group.loc[:, "client_tuple"] = group["fd.name"].apply(
            lambda x: f"{connection_re.match(x).group(1)}({connection_re.match(x).group(2)})"
            if connection_re.match(x) else None
        )
        group.loc[:, "client_tuple"] = group["client_tuple"].ffill()
        return group
    
    def process_group(group: pd.DataFrame) -> pd.DataFrame:
        # 只保留fd.name=/var/log/mysql/mysql.log以及evt.type=recvfrom的行
        group = group[(group["fd.name"] == "/var/log/mysql/mysql.log") | (group["evt.type"] == "recvfrom")]
        if group.empty:
            return group
        group = extract_tuple(group)
        group = group[(group["fd.name"] == "/var/log/mysql/mysql.log") & (group["evt.arg.data"].str.contains("Query"))]
        return group
    
    # processed_data = []
    data = data.groupby("thread.tid", sort=False).apply(process_group)

    # if not processed_data:
    #     return pd.DataFrame()
    # data = pd.concat(processed_data, ignore_index=True)
    data = data.sort_values("evt.datetime")
    data = data.reset_index(drop=True)
    # 提取数据库语句
    log_re = re.compile(r".*Query\.(.+)")
    data["statement"] = data["evt.arg.data"].apply(
        lambda x: (log_re.match(x).group(1).replace('.', ' ').strip() + ";").replace("`", "") if log_re.match(x) else None
    )

    # return data
    # 只返回 INSERT、UPDATE、DELETE 语句
    return data[data["statement"].str.startswith(("INSERT", "UPDATE", "DELETE"))].reset_index(drop=True)


def extract_tuple_for_single_request(data: pd.DataFrame) -> pd.DataFrame:
    # 提取数据库连接
    connection_re = re.compile(
        r"(\d+.\d+.\d+.\d+):(\d+)->(\d+.\d+.\d+.\d+):3306"
    )
    # fd.name为None的行补为空字符串
    try:
        data["fd.name"] = data["fd.name"].fillna("NULL")
    except:
        # print(data)
        raise
    data["client_tuple"] = data["fd.name"].apply(
        lambda x: f"{connection_re.match(x).group(1)}({connection_re.match(x).group(2)})"
        if connection_re.match(x) else None
    )
    data["client_tuple"] = data["client_tuple"].ffill()
    data["client_tuple"] = data["client_tuple"].bfill()
    return data


HTTP_METHODS = ["GET", "POST", "HEAD", "PUT", "DELETE", "OPTIONS", "PATCH", "CONNECT", "TRACE"]
def extract_request_syscalls(grouped_data):
    length = 0
    request_data_dict: dict[str, list] = {}
    for name, group in grouped_data:
        if str(name) == "1":
            continue
        in_request = False
        request_id = 0
        current_fd = None
        request_info = None
        # 针对每个进程
        # group.to_json(f"request_data/{name}.jsonl", orient="records", lines=True)
        for _, row in group.iterrows():
            # 根据accept4和close事件来判断请求的开始和结束
            if row["evt.type"] == "read" and row["evt.category"] == "net" and not row["fd.name"].startswith("127.0.0.1") and row["evt.arg.data"].split(" ")[0] in HTTP_METHODS:
                res = re.search(r"res=([1-9]\d*)", row["evt.info"])
                if not res:
                    continue
                length += 1
                if in_request:
                    request_data_dict[f"{name}-{request_id}"] = pd.DataFrame(request_data_dict[f"{name}-{request_id}"])
                    request_data_dict[f"{name}-{request_id}"]["request_info"] = request_info
                    request_info = None
                in_request = True
                current_fd = row["fd.name"]
                request_id += 1
                request_data_dict[f"{name}-{request_id}"] = []
            if in_request:
                request_data_dict[f"{name}-{request_id}"].append(row)
                if row["evt.type"] == "read" and row["evt.category"] == "net" and row["fd.name"] == current_fd:
                    if not request_info:
                        request_info = ""
                    request_info += row["evt.arg.data"]

            if row["evt.type"] == "writev" and row["fd.name"] == current_fd:
                in_request = False
                current_fd = None
                # 把数据转换为DataFrame
                request_data_dict[f"{name}-{request_id}"] = pd.DataFrame(request_data_dict[f"{name}-{request_id}"])
                request_data_dict[f"{name}-{request_id}"]["request_info"] = request_info
                request_info = None
    print("length:", length)
    return request_data_dict

if __name__ == "__main__":
    os.system("rm -f ./request_data/*")

    data = data[data["evt.type"] != "close"]
    # evt.type 为open或openat，且("O_F_CREATED" not in row["evt.info"]) and ("O_TRUNC" not in row["evt.info"])的行舍弃
    data = data[~data["evt.type"].isin(["open", "openat"]) | (
        data["evt.info"].str.contains("O_F_CREATED") | data["evt.info"].str.contains("O_TRUNC")
    )]
    proc_group = data.groupby("proc.name", sort=False)
    mysql_data = proc_group.get_group("mysqld")
    mysql_data = analyze_mysql_data(mysql_data)

    apache_data = proc_group.get_group("apache2")
    # data按thread.tid分组
    grouped_data = apache_data.groupby("proc.vpid", sort=False)

    request_data_dict = extract_request_syscalls(grouped_data)
    
    aggregated_data = pd.DataFrame()
    print("request_data_dict:", len(request_data_dict))
    for key, value in request_data_dict.items():
        # 提取每个请求的数据库连接
        request_data_dict[key] = extract_tuple_for_single_request(value)
        request_data_dict[key]["request_id"] = key
        aggregated_data = pd.concat([aggregated_data, request_data_dict[key]])

    aggregated_data = pd.concat([aggregated_data, mysql_data])
    def match_id_database(group: pd.DataFrame) -> pd.DataFrame:
        group = group.sort_values("evt.datetime")
        group["request_id"] = group["request_id"].ffill()
        group["request_id"] = group["request_id"].bfill()
        group["request_info"] = group["request_info"].ffill()
        group["request_info"] = group["request_info"].bfill()
        return group
    matched_data = aggregated_data.groupby("client_tuple", sort=False).apply(
        match_id_database, include_groups=True
    ).groupby("proc.name", sort=False).get_group("mysqld").sort_values("evt.datetime")
    matched_data.to_json("matched_data.jsonl", orient="records", lines=True)
    # 将matched_data中的request_id和statement用字典形式输出, result[request_id] = [statement1, statement2]
    result = {}
    for _, row in matched_data.iterrows():
        if str(row["request_id"]) == "NaN":
            continue
        if row["request_id"] not in result:
            result[row["request_id"]] = {
                "request_info": row["request_info"],
                "statement": []
            }
        if row["statement"] and row["statement"].split(" ", 1)[0] in ["INSERT", "UPDATE", "DELETE"] and "j_session" not in row["statement"]:
            result[row["request_id"]]["statement"].append(row["statement"])
    
    def statement_filter(statement: str):
        tables = statement.split(" ")
        if "j_contentitem_tag_map" in tables:
            return True
        if "j_ucm_history" in tables:
            if "INSERT" in statement:
                return False
            return True
        if "j_content" in tables:
            if "SET ordering" in statement or "asset_id" in statement:
                return False
            return True
        return False
        
    # 过滤，只保留主数据表操作
    for key in list(result.keys()):
        if not result[key]["statement"]:
            del result[key]
            continue
        for i in range(len(result[key]["statement"]) - 1, -1, -1):
            if not statement_filter(result[key]["statement"][i]):
                result[key]["statement"].pop(i)

    print("result:", len(result))
    # 将结果输出为json格式
    with open("db_results.json", "w") as f:
        json.dump(result, f, indent=2)
