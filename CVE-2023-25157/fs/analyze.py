import pandas as pd
from ProvGraph import ProvGraph, ProcNode, FileNode, RequestNode, EdgeType
import os
import json
import re


DEBUG = False
DRAW_GRAPH = False

if DEBUG:
    pd.set_option('display.max_columns', None)
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_colwidth', None)

total = pd.read_json("./capture/capture.jsonl", lines=True, dtype={"proc.vpid": str, "proc.cvpid": str, "proc.pvpid": str, "thread.vtid": str,
                                                                   "thread.pvtid": str, "thread.cvtid": str})

# 去掉mysql的行
total = total[total["proc.name"] != "postgres"]

def get_unique_ordered_names(group):  
    # 保持顺序的唯一值提取  
    names = []  
    for name in group['proc.name']:  
        if name not in names:  
            names.append(name)  
    return names 
    

unique_names = total.groupby("thread.vtid", sort=False).apply(get_unique_ordered_names)

for vpid, names in unique_names.items():
    if len(names) == 1:
        continue
    # 把多个名字的进程用->连接起来
    new_name = "->".join(names)
    total.loc[total["thread.vtid"] == vpid, "proc.name"] = new_name

proc_groups = total.groupby("thread.vtid", sort=False)
JV_THREADs = {}

def get_grouped_data(data: pd.DataFrame) -> dict:
    return data.groupby("thread.vtid", sort=False)


def analyze_request_files(request_id: str, data: pd.DataFrame) -> ProvGraph:
    # 迭代每一行，寻找type=file的行
    graph = ProvGraph()
    graph.add_node(RequestNode(request_id))
    file_data = data[(data["evt.category"] == "file") & (data["fd.name"] != "/dev/null")]
    # print(file_data)
    unmatched_copy = None
    for _, row in file_data.iterrows():
        if row["evt.type"] == "read" or row["evt.type"] == "pread":
            pass
            # graph.add_event_edge(FileNode(row["fd.name"], row["fd.type"] == "directory"), RequestNode(request_id), EdgeType.READ, row["evt.datetime"])
        elif row["evt.type"] == "write" or row["evt.type"] == "pwrite" \
             or ((row["evt.type"] == "open" or row["evt.type"] == "openat") and ("O_F_CREATED" not in row["evt.info"]) and ("O_TRUNC" in row["evt.info"])):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.WRITE, row["evt.datetime"], row["evt.arg.data"])
        elif row["evt.type"] == "copy_file_range":
            if row["evt.dir"] == ">":
                unmatched_copy = (FileNode(row["fd.name"], row["fd.type"] == "directory"), RequestNode(request_id), EdgeType.COPY_FROM, row["evt.datetime"])
            elif row["evt.dir"] == "<":
                if unmatched_copy is not None:
                    # graph.add_event_edge(*unmatched_copy)
                    graph.add_event_edge(RequestNode(request_id), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY_TO, row["evt.datetime"])
                    graph.add_event_edge(FileNode(unmatched_copy[0].name), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY, row["evt.datetime"])
                    unmatched_copy = None
        elif (row["evt.type"] == "open" or row["evt.type"] == "openat") and "O_F_CREATED" in row["evt.info"]:
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.CREATE, row["evt.datetime"])
        elif (row["evt.type"] == "unlink" or row["evt.type"] == "unlinkat") and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.DELETE, row["evt.datetime"])
        elif (row["evt.type"] == "chmod") and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.CHMOD, row["evt.datetime"])
        elif (row["evt.type"] == "chown") and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.CHOWN, row["evt.datetime"])
        elif row["evt.type"] == "mkdir" and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.MKDIR, row["evt.datetime"])
        elif row["evt.type"] == "rmdir" and row["evt.info"].startswith("res=0"):
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.name"]), EdgeType.RMDIR, row["evt.datetime"])
        elif (row["evt.type"] == "renameat2" or row["evt.type"] == "renameat" or row["evt.type"] == "rename") and row["evt.info"].startswith("res=0"):
            # graph.add_event_edge(FileNode(row["fs.path.source"]), RequestNode(request_id), "rename_source", row["evt.datetime"])
            graph.add_event_edge(RequestNode(request_id), FileNode(row["fs.path.target"]), EdgeType.RENAME_TARGET, row["evt.datetime"])
            graph.add_event_edge(FileNode(row["fs.path.source"]), FileNode(row["fs.path.target"]), EdgeType.RENAME, row["evt.datetime"])
    
    return graph


def analyze_request_subprocesses(data: pd.DataFrame) -> list:
    request_subprocesses = []
    subprocess_data = data[(data["evt.type"] == "clone") | (data["evt.type"] == "vfork")]
    # print(subprocess_data)
    for _, row in subprocess_data.iterrows():
        request_subprocesses.append(row["thread.cvtid"])
    
    return request_subprocesses


HTTP_METHODS = ["GET", "POST", "HEAD", "PUT", "DELETE", "OPTIONS", "PATCH", "CONNECT", "TRACE"]
def analyze_single_process_data(name: str, group: pd.DataFrame) -> tuple[dict[str, ProvGraph], dict[str, str], dict[str, str]]:
    group.to_json(f"request_data/{name}.jsonl", orient="records", lines=True)
    request_data_dict: dict[str, list] = {}
    in_request = False
    request_id = 0
    current_fd = None
    request_info = None
    current_JV_THREADs = set()
    sub_JV_THREADs = []
    # group.to_json(f"request_data/{name}.jsonl", orient="records", lines=True)
    for _, row in group.iterrows():
        # 根据accept4和close事件来判断请求的开始和结束
        if type(row["evt.arg.data"]) == str:
            if row["evt.arg.data"].startswith("JV_RUN_START"):
                jv_thread = row["evt.arg.data"].replace("JV_RUN_START ", "")
                current_JV_THREADs.add(jv_thread)
                if jv_thread not in JV_THREADs:
                    JV_THREADs[jv_thread] = []
                if jv_thread in sub_JV_THREADs:
                    sub_JV_THREADs.remove(jv_thread)
            if row["evt.arg.data"].startswith("JV_RUN_END"):
                jv_thread = row["evt.arg.data"].replace("JV_RUN_END ", "")
                # current_JV_THREADs.remove(jv_thread)
                current_JV_THREADs.discard(jv_thread)
        
        for jv_thread in current_JV_THREADs:
            JV_THREADs[jv_thread].append(row)
        

        if row["evt.type"] == "read" and row["evt.category"] == "net" and not row["fd.name"].startswith("127.0.0.1") and row["evt.arg.data"].split(" ")[0] in HTTP_METHODS:
            res = re.search(r"res=([1-9]\d*)", row["evt.info"])
            if not res:
                continue
            if in_request:
                request_data_dict[f"{name}-{request_id}"] = pd.DataFrame(request_data_dict[f"{name}-{request_id}"])
                request_data_dict[f"{name}-{request_id}"]["request_info"] = request_info
                request_data_dict[f"{name}-{request_id}"]["sub_JV_THREADs"] = str(sub_JV_THREADs)
                sub_JV_THREADs = []
                request_info = None
            in_request = True
            current_fd = row["fd.name"]
            request_id += 1
            request_data_dict[f"{name}-{request_id}"] = []
        if in_request:
            request_data_dict[f"{name}-{request_id}"].append(row)
            if row["evt.type"] == "read" and row["evt.category"] == "net" and row["fd.name"] == current_fd:
                if not request_info:
                    request_info = ""
                request_info += row["evt.arg.data"]
            if type(row["evt.arg.data"]) == str and row["evt.arg.data"].startswith("JV_CREATE"):
                jv_thread = row["evt.arg.data"].replace("JV_CREATE ", "")
                sub_JV_THREADs.append(jv_thread)

        if row["evt.type"] == "writev" and row["evt.category"]=="net" and row["fd.name"] == current_fd:
            in_request = False
            current_fd = None
            # 把数据转换为DataFrame
            request_data_dict[f"{name}-{request_id}"] = pd.DataFrame(request_data_dict[f"{name}-{request_id}"])
            request_data_dict[f"{name}-{request_id}"]["request_info"] = request_info
            request_data_dict[f"{name}-{request_id}"]["sub_JV_THREADs"] = str(sub_JV_THREADs)
            sub_JV_THREADs = []
            request_info = None
    if len(request_data_dict) == 0:
        print(f"Process {name} has no requests.")
        return None, None, None
    
    print(f"Process {name} has {len(request_data_dict)} requests.")
    # 按照request_id分组
    result = ({}, {})
    result_info_map = {}
    sub_jv_thread_map = {}
    for request_id, group in request_data_dict.items():
        print(f"Analyzing request {request_id}")
        request_graph = analyze_request_files(request_id, group)
        result[0][request_id] = request_graph
        request_subprocesses = analyze_request_subprocesses(group)
        result[1][request_id] = request_subprocesses
        result_info_map[request_id] = group.iloc[0]["request_info"]
        sub_jv_thread_map[request_id] = group.iloc[0]["sub_JV_THREADs"]
        group.drop(columns=["request_info", "sub_JV_THREADs"], inplace=True)
        group.to_json(f"request_data/{request_id}.jsonl", orient="records", lines=True)

    return result, result_info_map, sub_jv_thread_map


def build_graph(request_id: str, vpids: list, jv_tids: list, graph: ProvGraph | None = None) -> ProvGraph:
    graph = ProvGraph() if graph is None else graph
    graph.add_node(RequestNode(request_id))
    unmatched_copy = None
    for vpid in vpids:
        try:
            proc_data = proc_groups.get_group(vpid)
            graph.add_event_edge(RequestNode(request_id), ProcNode(vpid, proc_data.iloc[0]["proc.name"]), EdgeType.CREATE_SUBPROCESS, proc_data.iloc[0]["evt.datetime"])
        except KeyError:
            # graph.add_event_edge(RequestNode(request_id), ProcNode(vpid, "unknown"), EdgeType.CREATE_SUBPROCESS, proc_data.iloc[0]["evt.datetime"])
            continue
    for jv_tid in jv_tids:
        try:
            proc_data = JV_THREADs[jv_tid]
            graph.add_event_edge(RequestNode(request_id), ProcNode(jv_tid, "JV_THREAD"), EdgeType.CREATE_SUBPROCESS, proc_data.iloc[0]["evt.datetime"])
        except KeyError:
            # graph.add_event_edge(RequestNode(request_id), ProcNode(jv_tid, "unknown"), EdgeType.CREATE_SUBPROCESS, proc_data.iloc[0]["evt.datetime"])
            continue
    # while len(vpids) > 0:
    #     vpid = vpids.pop()
        # try:
        #     proc_data = proc_groups.get_group(vpid)
        # except KeyError:
        #     continue
    def build(proc_data: pd.DataFrame, proc_node: ProcNode):
        for _, row in proc_data.iterrows():
            if row["evt.category"] == "file" and row["fd.name"] != "/dev/null":
                if row["evt.type"] == "read" or row["evt.type"] == "pread":
                    pass
                    # graph.add_event_edge(FileNode(row["fd.name"], row["fd.type"] == "directory"), proc_node, EdgeType.READ, row["evt.datetime"])
                elif row["evt.type"] == "write" or row["evt.type"] == "pwrite" \
                    or ((row["evt.type"] == "open" or row["evt.type"] == "openat") and ("O_F_CREATED" not in row["evt.info"]) and ("O_TRUNC" in row["evt.info"])):
                    graph.add_event_edge(proc_node, FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.WRITE, row["evt.datetime"], row["evt.arg.data"])
                elif row["evt.type"] == "copy_file_range":
                    if row["evt.dir"] == ">":
                        unmatched_copy = (FileNode(row["fd.name"], row["fd.type"] == "directory"), proc_node, EdgeType.COPY_FROM, row["evt.datetime"])
                    elif row["evt.dir"] == "<":
                        if unmatched_copy is not None:
                            # graph.add_event_edge(*unmatched_copy)
                            graph.add_event_edge(proc_node, FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY_TO, row["evt.datetime"])
                            graph.add_event_edge(FileNode(unmatched_copy[0].name), FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.COPY, row["evt.datetime"])
                            unmatched_copy = None
                elif (row["evt.type"] == "open" or row["evt.type"] == "openat") and "O_F_CREATED" in row["evt.info"]:
                    graph.add_event_edge(proc_node, FileNode(row["fd.name"], row["fd.type"] == "directory"), EdgeType.CREATE, row["evt.datetime"])
                elif (row["evt.type"] == "unlink" or row["evt.type"] == "unlinkat") and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(proc_node, FileNode(row["fs.path.name"]), EdgeType.DELETE, row["evt.datetime"])
                elif (row["evt.type"] == "chmod") and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(proc_node, FileNode(row["fs.path.name"]), EdgeType.CHMOD, row["evt.datetime"])
                elif (row["evt.type"] == "chown") and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(proc_node, FileNode(row["fs.path.name"]), EdgeType.CHOWN, row["evt.datetime"])
                elif row["evt.type"] == "mkdir" and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(proc_node, FileNode(row["fs.path.name"]), EdgeType.MKDIR, row["evt.datetime"])
                elif row["evt.type"] == "rmdir" and row["evt.info"].startswith("res=0"):
                    graph.add_event_edge(proc_node, FileNode(row["fs.path.name"]), EdgeType.RMDIR, row["evt.datetime"])
                elif (row["evt.type"] == "renameat2" or row["evt.type"] == "renameat" or row["evt.type"] == "rename") and row["evt.info"].startswith("res=0"):
                    # graph.add_event_edge(FileNode(row["fs.path.source"]), proc_node, "rename_source", row["evt.datetime"])
                    graph.add_event_edge(proc_node, FileNode(row["fs.path.target"]), EdgeType.RENAME_TARGET, row["evt.datetime"])
                    graph.add_event_edge(FileNode(row["fs.path.source"]), FileNode(row["fs.path.target"]), EdgeType.RENAME, row["evt.datetime"])
            if row["evt.type"] == "clone" or row["evt.type"] == "vfork":
                try:
                    cproc_data = proc_groups.get_group(row["thread.cvtid"])
                    vpids.append(row["thread.cvtid"])
                    graph.add_event_edge(proc_node, ProcNode(row["thread.cvtid"], cproc_data.iloc[0]["proc.name"]), EdgeType.CREATE_SUBPROCESS, row["evt.datetime"])
                except KeyError:
                    graph.add_event_edge(proc_node, ProcNode(row["thread.cvtid"], "unknown"), EdgeType.CREATE_SUBPROCESS, row["evt.datetime"])

            if type(row["evt.arg.data"]) == str and row["evt.arg.data"].startswith("JV_CREATE"):
                jv_thread = row["evt.arg.data"].replace("JV_CREATE ", "")
                if jv_thread not in JV_THREADs:
                    print(f"JV_THREAD {jv_thread} not found in JV_THREADs")
                    continue
                jv_tids.append(jv_thread)
                graph.add_event_edge(proc_node, ProcNode(jv_thread, "JV_THREAD"), EdgeType.CREATE_SUBPROCESS, row["evt.datetime"])
    
    while len(vpids) > 0 or len(jv_tids) > 0:
        if len(vpids) > 0:
            vpid = vpids.pop()
            try:
                proc_data = proc_groups.get_group(vpid)
            except KeyError:
                continue
            build(proc_data, ProcNode(vpid, proc_data.iloc[0]["proc.name"]))
        if len(jv_tids) > 0:
            jv_tid = jv_tids.pop()
            try:
                proc_data = JV_THREADs[jv_tid]
            except KeyError:
                continue
            build(proc_data, ProcNode(jv_tid, "JV_THREAD"))
    return graph
            

def analyze_results():
    results = {}
    req_info = {}
    matchare_res = {}
    graph_map = {}
    total_requests = 0


    grouped_data = get_grouped_data(total)
    os.system("rm -rf ./prov_graphs/*")
    os.system("rm -rf ./request_data/*")
    # file_data = total[(total["evt.category"] == "file")]
    # # 去掉fd.name为NaN的行
    # file_data = file_data[file_data["fd.name"].notna()]
    # # 只保留fd.name 以/var/www/html/images/data/开头的行
    # file_data = file_data[file_data["fd.name"].str.startswith("/var/www/html/images/data/")]
    # file_data.to_json("request_data/file_data.jsonl", orient="records", lines=True)

    for name, group in grouped_data:
        print(f"Analyzing process {name}")
        analyzed_data, req_info_map, sub_jv_map = analyze_single_process_data(name, group)
        if analyzed_data is not None:
            req_info |= req_info_map
            total_requests += len(analyzed_data[0])
            for request_id, vpids in analyzed_data[1].items():
                graph = analyzed_data[0][request_id]
                # graph = build_graph(request_id, vpids, graph)
                graph_map[request_id] = (graph, sub_jv_map[request_id], vpids)
                # if DRAW_GRAPH:
                #     graph.draw_graph(file_name=f"prov_graph_{request_id}", show=False, save_path="./prov_graphs/")
                # affected_files = graph.find_affected_files(RequestNode(request_id))
                # results[request_id] = affected_files
                # matchare_res[request_id] = graph.find_related_files(RequestNode(request_id))

    for key, value in JV_THREADs.items():
        JV_THREADs[key] = pd.DataFrame(value)

    print(f"Total JV threads: {len(JV_THREADs)}")
    print(list(JV_THREADs.keys()))
    for request_id, (graph, jv_tids, vpids) in graph_map.items():
        jv_tids = eval(jv_tids)
        print(f"Building graph for request {request_id} with {len(vpids)} vpids and {len(jv_tids)} jv_tids")
        graph = build_graph(request_id, vpids, jv_tids, graph)
        # graph = build_graph(request_id, vpids, [], graph)
        affected_files = graph.find_affected_files(RequestNode(request_id))
        if not affected_files:
            print(f"No affected files found for request {request_id}")
            continue
        results[request_id] = affected_files
        matchare_res[request_id] = graph.find_related_files(RequestNode(request_id))
        if DRAW_GRAPH:
            graph.draw_graph(file_name=f"prov_graph_{request_id}", show=False, save_path="./prov_graphs/")
        # matchare_res[request_id] = [file for file in matchare_res[request_id] if not file["source_path"].endswith(".tmp")]


    print(f"Total requests: {total_requests}")
    print("Done!")
    with open("fs_results.json", "w") as out:
        out.write(json.dumps(results, indent=4))
    with open("req_info.json", "w") as out:
        out.write(json.dumps(req_info, indent=4))
    with open("matchare_res.json", "w") as out:
        out.write(json.dumps(matchare_res, indent=4))

    return results

if __name__ == "__main__":
    analyze_results()
    pass