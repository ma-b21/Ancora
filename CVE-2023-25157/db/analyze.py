from pprint import pprint
import re
import os
import pandas as pd
pd.set_option('future.no_silent_downcasting', True)  
import json

DEBUG = False

if DEBUG:
    pd.set_option('display.max_columns', None)
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_colwidth', None)

data = pd.read_json("./capture/capture.jsonl", lines=True, dtype={"proc.vpid": str, "proc.cvpid": str, "proc.pvpid": str, "thread.vtid": str, \
                                                                  "fd.cport": str, "fd.sport": str})

def analyze_postgres_data(data: pd.DataFrame) -> pd.DataFrame:
    log_re_detail = re.compile(
        r".*?\[([0-9\.]+\(\d+\))\].*?LOG:\s+.*?:\s*(.*)\.\d+\..*\[[0-9\.]+\(\d+\)\].*?DETAIL:\s+(.*)", re.DOTALL
    )
    log_re = re.compile(
        r".*?\[([0-9\.]+\(\d+\))\].*?LOG:\s+.*?:\s*(.*)\.", re.DOTALL
    )

    data = data.copy()
    # 删除evt.arg.data中不包含LOG:的行和evt.arg.data为nan
    data = data[~data["evt.arg.data"].isna() & data["evt.arg.data"].str.contains("LOG:")]

    def extract_fields(row):
        if "DETAIL:" in row["evt.arg.data"]:
            match = log_re_detail.match(row["evt.arg.data"])
        else:
            match = log_re.match(row["evt.arg.data"])
        if match:
            if len(match.groups()) == 3:
                # LOG: [client_tuple] statement.
                # DETAIL: details
                return pd.Series({
                    "client_tuple": match.group(1),
                    "statement": match.group(2),
                    "details": match.group(3)
                })
            elif len(match.groups()) == 2:
                # LOG: [client_tuple] statement.
                # 没有DETAIL
                return pd.Series({
                    "client_tuple": match.group(1),
                    "statement": match.group(2),
                    "details": None
                })
            
        return pd.Series({
            "client_tuple": None,
            "statement": None,
            "details": None
        })

    data[["client_tuple", "statement", "details"]] = data.apply(extract_fields, axis=1)
    # 非数据库日志丢弃
    data = data[data["evt.arg.data"].apply(
        lambda x: "LOG:" in x and "execute" in x
    )]
    
    for index, row in data.iterrows():
        if row["details"] and row["details"].startswith("parameters: "):
            details_str = row["details"][len("parameters: "):]
            print(f"details_str: {details_str}")
            params = [p.split("=", 1) for p in details_str.strip(" .").split(", $")]
            print(f"params: {params}")
            parameters = {'$' + k.strip('$ '): v.strip() for k, v in params}
            statement = row["statement"]
            for key, value in reversed(parameters.items()):
                statement = statement.replace(key, value)
            data.loc[index, "statement"] = statement
        
        data.loc[index, "statement"] = data.loc[index, "statement"].replace("..", " ").split("--")[0].strip()  # 转义单引号

    return data.drop(columns=["details"], errors='ignore').reset_index(drop=True)

def extract_tuple_for_single_request(data: pd.DataFrame) -> pd.DataFrame:
    # 提取数据库连接
    connection_re = re.compile(
        r"(\d+.\d+.\d+.\d+):(\d+)->(\d+.\d+.\d+.\d+):5432"
    )
    # fd.name为None的行补为空字符串
    try:
        data["fd.name"] = data["fd.name"].fillna("NULL")
    except:
        # print(data)
        raise
    # 如果fd.name="<unknown>"，则替换为f"row["fd.cip"]}:{row["fd.cport"]}->{row["fd.sip"]}:{row["fd.sport"]}"
    def fill_fd_name(row):
        if row["fd.name"] == "<unknown>":
            if pd.notna(row["fd.cip"]) and pd.notna(row["fd.cport"]) and pd.notna(row["fd.sip"]) and pd.notna(row["fd.sport"]):
                return f"{row['fd.cip']}:{row['fd.cport']}->{row['fd.sip']}:{row['fd.sport']}"
            else:
                return "NULL"
        else:
            return row["fd.name"]

    data["fd.name"] = data.apply(fill_fd_name, axis=1)

    data["client_tuple"] = data["fd.name"].apply(
        lambda x: f"{connection_re.match(x).group(1)}({connection_re.match(x).group(2)})"
        if connection_re.match(x) else None
    )
    # data["client_tuple"] = data["client_tuple"].ffill()
    # data["client_tuple"] = data["client_tuple"].bfill()
    data = data[data["client_tuple"].notna()]
    return data


HTTP_METHODS = ["GET", "POST", "HEAD", "PUT", "DELETE", "OPTIONS", "PATCH", "CONNECT", "TRACE"]
def extract_request_syscalls(grouped_data) -> dict:
    length = 0
    request_data_dict: dict[str, list] = {}
    for name, group in grouped_data:
        # group.to_json(f"request_data/{name}.jsonl", orient="records", lines=True)
        in_request = False
        request_id = 0
        current_fd = None
        request_info = None
        # 针对每个进程
        # group.to_json(f"request_data/{name}.jsonl", orient="records", lines=True)
        for _, row in group.iterrows():
            # 根据accept4和close事件来判断请求的开始和结束
            if row["fd.name"] == "<unknown>":
                row["fd.name"] = f"{row['fd.cip']}:{row['fd.cport']}->{row['fd.sip']}:{row['fd.sport']}" if pd.notna(row["fd.cip"]) and pd.notna(row["fd.cport"]) and pd.notna(row["fd.sip"]) and pd.notna(row["fd.sport"]) else "NULL"
            # if type(row['evt.arg.data']) == str and row['evt.arg.data'].startswith("JV_RUN_START") and row['evt.arg.data'].endswith("SocketWrapperBase"):
            if row["evt.type"] == "read" and row["evt.category"] == "net" and not row["fd.name"].startswith("127.0.0.1") and row["evt.arg.data"].split(" ")[0] in HTTP_METHODS:
                res = re.search(r"res=([1-9]\d*)", row["evt.info"])
                if not res:
                    continue
                length += 1
                if in_request:
                    request_data_dict[f"{name}-{request_id}"] = pd.DataFrame(request_data_dict[f"{name}-{request_id}"])
                    request_data_dict[f"{name}-{request_id}"]["request_info"] = request_info
                    request_info = None
                in_request = True
                current_fd = row["fd.name"]
                request_id += 1
                request_data_dict[f"{name}-{request_id}"] = []
            if in_request:
                request_data_dict[f"{name}-{request_id}"].append(row)
                if row["evt.type"] == "read" and row["evt.category"] == "net" and row["fd.name"] == current_fd:
                    if not request_info:
                        request_info = ""
                    request_info += row["evt.arg.data"]

            # if row["evt.type"] == "write" and row["evt.category"]=="net" and row["fd.name"] == current_fd:
            # if row["evt.arg.data"] == "JV_RUN_END 0SocketWrapperBase":
            #     in_request = False
            #     # 把数据转换为DataFrame
            #     request_data_dict[f"{name}-{request_id}"] = pd.DataFrame(request_data_dict[f"{name}-{request_id}"])
            #     request_data_dict[f"{name}-{request_id}"]["request_info"] = request_info
            #     request_info = None
            #     current_fd = None
        if request_info:
            request_data_dict[f"{name}-{request_id}"] = pd.DataFrame(request_data_dict[f"{name}-{request_id}"])
            request_data_dict[f"{name}-{request_id}"]["request_info"] = request_info
    print("length:", length)
    return request_data_dict

if __name__ == "__main__":
    os.system("rm -f ./request_data/*")

    data = data[data["evt.type"] != "close"]
    # evt.type 为open或openat，且("O_F_CREATED" not in row["evt.info"]) and ("O_TRUNC" not in row["evt.info"])的行舍弃
    data = data[~data["evt.type"].isin(["open", "openat"]) | (
        data["evt.info"].str.contains("O_F_CREATED") | data["evt.info"].str.contains("O_TRUNC")
    )]
    proc_group = data.groupby("proc.name", sort=False)
    postgres_data = proc_group.get_group("postgres")
    postgres_data = analyze_postgres_data(postgres_data)
    print("postgres_data:", len(postgres_data))
    # postgres_data.to_json("request_data/postgres_data.jsonl", orient="records", lines=True)

    server_data = data[~data["proc.name"].isin(["postgres", "mysqld"])]
    # apache_data.to_json("request_data/apache_data.jsonl", orient="records", lines=True)
    # data按thread.tid分组
    grouped_data = server_data.groupby("thread.vtid", sort=False)

    request_data_dict = extract_request_syscalls(grouped_data)
    aggregated_data = pd.DataFrame()
    print("request_data_dict:", len(request_data_dict))

    for key, value in request_data_dict.items():
        # 提取每个请求的数据库连接
        if type(value) is not pd.DataFrame:
            value = pd.DataFrame(value)
        request_data_dict[key] = extract_tuple_for_single_request(value).copy()
        request_data_dict[key].loc[:, "request_id"] = key
        # request_data_dict[key].to_json(f"request_data/{key}.jsonl", orient="records", lines=True)
        aggregated_data = pd.concat([aggregated_data, request_data_dict[key]])

    aggregated_data = pd.concat([aggregated_data, postgres_data])
    # aggregated_data.to_json("request_data/aggregated_data.jsonl", orient="records", lines=True)
    def match_id_database(group: pd.DataFrame) -> pd.DataFrame:
        group = group.sort_values("evt.datetime")
        group["request_id"] = group["request_id"].ffill()
        group["request_id"] = group["request_id"].bfill()
        group["request_info"] = group["request_info"].ffill()
        group["request_info"] = group["request_info"].bfill()
        # group.to_json(f"request_data/{group.iloc[0]['client_tuple']}.jsonl", orient="records", lines=True)
        return group
    matched_data = aggregated_data.groupby("client_tuple", sort=False).apply(
        match_id_database, include_groups=True
    ).groupby("proc.name", sort=False).get_group("postgres").sort_values("evt.datetime")
    matched_data.to_json("matched_data.jsonl", orient="records", lines=True)
    print("matched_data:", len(matched_data))
    # 将matched_data中的request_id和statement用字典形式输出, result[request_id] = [statement1, statement2]
    result = {}
    for _, row in matched_data.iterrows():
        if str(row["request_id"]) == "NaN":
            continue
        if row["request_id"] not in result:
            result[row["request_id"]] = {
                "request_info": row["request_info"],
                "statement": []
            }
        if row["statement"] and "SERVER_HIT_BIN" not in row["statement"] and "SEQUENCE_VALUE_ITEM" not in row["statement"]:
            result[row["request_id"]]["statement"].append(row["statement"])
    
    # 如果"statement"为空，则删除该条记录
    for key in list(result.keys()):
        if len(result[key]["statement"]) != 1:
            print(f"ERROR: request_id: {key}, statement: {result[key]['statement']}")

    print("result:", len(result))
    # 将结果输出为json格式
    with open("db_results.json", "w") as f:
        json.dump(result, f, indent=2)

